{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTjjt8VpPwEB4TyrPClTVA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaqas86/Langgraph_EcoSystem/blob/main/PanaversityConversational_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langsmith langchain_google_genai langchain_community"
      ],
      "metadata": {
        "id": "ll1QplWLbpKx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"DLIMS-Agentic-System\"\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')\n",
        "\n",
        "gemini_api_key = userdata.get('GEMINI_API_KEY')\n",
        "tavily_api_key = userdata.get('TAVILY_API_KEY')"
      ],
      "metadata": {
        "id": "vw0vvVXAb3_q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "\n",
        "llm.invoke(\"greet me\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skyhe1rvcBFg",
        "outputId": "0815ad34-6b5d-4295-e84b-3cf254229d1b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello there!  How are you doing today?\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-c867db6c-873f-4962-a521-4114c4ff985f-0', usage_metadata={'input_tokens': 3, 'output_tokens': 11, 'total_tokens': 14, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nheYdAShbiAe"
      },
      "outputs": [],
      "source": [
        "from typing import Optional, Dict, Any, List\n",
        "from langgraph.graph import StateGraph, END, START\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langchain_core.tools import BaseTool\n",
        "from pydantic import BaseModel, Field\n",
        "from typing_extensions import override,TypedDict\n",
        "\n",
        "# Define the application state\n",
        "class State(TypedDict):\n",
        "    messages: List[Dict[str, str]]\n",
        "    user_profile: Dict[str, Any]\n",
        "    profile_completion_stage: Optional[str]\n",
        "\n",
        "# Custom Tool Classes\n",
        "class LinkedInProfileTool(BaseTool):\n",
        "    name: str = Field(default=\"linkedin_profile\", description=\"Fetch professional profile data\")\n",
        "    description: str = \"Tool to extract professional information from LinkedIn profile\"\n",
        "\n",
        "    @override\n",
        "    def _run(self, linkedin_url: str, *args: Any, **kwargs: Any) -> Any:\n",
        "        # Simulated LinkedIn profile data extraction\n",
        "        # In a real-world scenario, this would use LinkedIn API or web scraping\n",
        "        return {\n",
        "            \"name\": \"Sample Professional\",\n",
        "            \"about\": \"Passionate tech enthusiast with 5+ years of experience\",\n",
        "            \"work_experience\": [\n",
        "                {\n",
        "                    \"company\": \"Tech Innovations Inc.\",\n",
        "                    \"role\": \"Senior Software Engineer\",\n",
        "                    \"duration\": \"2020-Present\"\n",
        "                }\n",
        "            ],\n",
        "            \"education\": [\n",
        "                {\n",
        "                    \"institution\": \"Tech University\",\n",
        "                    \"degree\": \"Computer Science\",\n",
        "                    \"graduation_year\": 2020\n",
        "                }\n",
        "            ],\n",
        "            \"skills\": [\"Python\", \"Machine Learning\", \"AI\", \"Data Science\"],\n",
        "        }\n",
        "\n",
        "class ProfileCompletionTool(BaseTool):\n",
        "    name: str = Field(default=\"profile_completion\", description=\"Complete user profile\")\n",
        "    description: str = \"Tool to guide and complete user profile information\"\n",
        "\n",
        "    @override\n",
        "    def _run(self, state: State, *args: Any, **kwargs: Any) -> Any:\n",
        "        # Check profile completeness and provide guidance\n",
        "        profile = state.get(\"user_profile\", {})\n",
        "        missing_fields = []\n",
        "\n",
        "        required_fields = [\n",
        "            \"name\", \"email\", \"phone\",\n",
        "            \"about\", \"work_experience\",\n",
        "            \"education\", \"skills\",\n",
        "            \"interests\", \"hobbies\"\n",
        "        ]\n",
        "\n",
        "        for field in required_fields:\n",
        "            if not profile.get(field):\n",
        "                missing_fields.append(field)\n",
        "\n",
        "        if missing_fields:\n",
        "            return f\"Please provide the following missing information: {', '.join(missing_fields)}\"\n",
        "\n",
        "        return {\"status\": \"Profile Complete\", \"profile\": profile}\n",
        "\n",
        "class PanaversityPromptEngineeringTool(BaseTool):\n",
        "    name: str = Field(default=\"prompt_engineering\", description=\"Generate interaction prompts\")\n",
        "    description: str = \"Tool to create specialized prompts for Panaversity agent interactions\"\n",
        "\n",
        "    @override\n",
        "    def _run(self, *args: Any, **kwargs: Any) -> Any:\n",
        "        # Generate a comprehensive system prompt for the Panaversity agent\n",
        "        return \"\"\"\n",
        "        You are a helpful AI assistant for Panaversity, dedicated to creating comprehensive student profiles.\n",
        "\n",
        "        Core Interaction Principles:\n",
        "        1. Be warm, encouraging, and professional\n",
        "        2. Guide students through profile creation step-by-step\n",
        "        3. Provide clear instructions and helpful suggestions\n",
        "        4. Validate and enrich provided information\n",
        "        5. Respect student privacy and data confidentiality\n",
        "\n",
        "        Profile Creation Flow:\n",
        "        - Introduce yourself and the profile creation process\n",
        "        - Ask for basic contact information\n",
        "        - Request professional background details\n",
        "        - Explore educational history\n",
        "        - Capture skills, interests, and career aspirations\n",
        "        - Offer personalized guidance based on provided information\n",
        "\n",
        "        Interaction Style:\n",
        "        - Use a conversational yet professional tone\n",
        "        - Ask open-ended questions to encourage detailed responses\n",
        "        - Provide examples when requesting specific information\n",
        "        - Offer constructive feedback and suggestions\n",
        "        \"\"\"\n",
        "\n",
        "# Instantiate tools\n",
        "tools = [\n",
        "    LinkedInProfileTool(),\n",
        "    ProfileCompletionTool(),\n",
        "    PanaversityPromptEngineeringTool()\n",
        "]\n",
        "\n",
        "# Dynamic tool selection\n",
        "def tools_condition(state: State):\n",
        "    profile = state.get(\"user_profile\", {})\n",
        "\n",
        "    if not profile.get(\"linkedin_data\"):\n",
        "        return \"linkedin_profile\"\n",
        "\n",
        "    if not profile.get(\"is_complete\"):\n",
        "        return \"profile_completion\"\n",
        "\n",
        "    return END\n",
        "\n",
        "# Build the graph\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Initialize state\n",
        "def initialize_state(state: State):\n",
        "    return {\n",
        "        \"messages\": state.get(\"messages\", []) + [\n",
        "            {\"role\": \"assistant\", \"content\": \"Welcome to Panaversity Profile Creator! Let's build your professional profile together.\"}\n",
        "        ],\n",
        "        \"user_profile\": state.get(\"user_profile\", {}),\n",
        "        \"profile_completion_stage\": \"start\"\n",
        "    }\n",
        "\n",
        "# Chatbot interaction node\n",
        "def chatbot_node(state: State):\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"] + [\n",
        "            {\"role\": \"assistant\", \"content\": \"How can I help you complete your profile today?\"}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "# Add nodes\n",
        "graph_builder.add_node(\"initialize\", initialize_state)\n",
        "graph_builder.add_node(\"chatbot\", chatbot_node)\n",
        "graph_builder.add_node(\"tools\", ToolNode(tools=tools))\n",
        "\n",
        "# Conditional routing\n",
        "def select_next_node(state: State):\n",
        "    return tools_condition(state)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    select_next_node,\n",
        "    {\"tools\": \"tools\", END: END},\n",
        ")\n",
        "\n",
        "# Add start and tool loops\n",
        "graph_builder.add_edge(START, \"initialize\")\n",
        "graph_builder.add_edge(\"initialize\", \"chatbot\")\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "\n",
        "# Compile graph\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(\n",
        "    checkpointer=memory\n",
        ")\n",
        "\n",
        "# Example interaction\n",
        "def run_profile_creation(input_message):\n",
        "    thread = {\"configurable\": {\"thread_id\": \"unique_user_session\"}}\n",
        "    inputs = {\"messages\": [{\"role\": \"human\", \"content\": input_message}]}\n",
        "    result = graph.invoke(inputs, thread)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "1eGNJIy_czLZ",
        "outputId": "4be2711c-8801-46b4-d66f-fb38e9a5f7ff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from typing import Dict, Any\n",
        "\n",
        "# Assuming the previous code is already imported and the graph is created\n",
        "# If not, make sure to include all the imports and graph creation code from the previous artifact\n",
        "\n",
        "# Async interaction method\n",
        "async def run_profile_creation_async(input_message: str) -> Dict[str, Any]:\n",
        "    thread = {\"configurable\": {\"thread_id\": \"unique_user_session\"}}\n",
        "    inputs = {\n",
        "        \"messages\": [{\"role\": \"human\", \"content\": input_message}],\n",
        "        \"user_profile\": {}  # Initialize with empty profile\n",
        "    }\n",
        "\n",
        "    # Use async invoke\n",
        "    result = await graph.ainvoke(inputs, thread)\n",
        "    return result\n",
        "\n",
        "# Synchronous wrapper for async method\n",
        "def run_profile_creation(input_message: str) -> Dict[str, Any]:\n",
        "    return asyncio.run(run_profile_creation_async(input_message))\n",
        "\n",
        "# Interactive conversation simulation\n",
        "def simulate_conversation():\n",
        "    print(\"Panaversity Profile Creator Agent\")\n",
        "    print(\"-------------------------------\")\n",
        "\n",
        "    # Conversation steps\n",
        "    conversation_steps = [\n",
        "        \"Hi, I want to create my Panaversity profile\",\n",
        "        \"My name is Ahmed Khan\",\n",
        "        \"I want to share my LinkedIn profile\",\n",
        "        \"https://linkedin.com/in/sample-profile\",\n",
        "        \"I'm interested in AI and Machine Learning\",\n",
        "        \"I graduated from FAST NUCES in Computer Science\",\n",
        "        \"My skills include Python, Machine Learning, and Data Science\",\n",
        "        \"I'm looking to join Panaversity's AI program\"\n",
        "    ]\n",
        "\n",
        "    # Store conversation history\n",
        "    conversation_history = []\n",
        "\n",
        "    # Simulate conversation\n",
        "    for user_input in conversation_steps:\n",
        "        print(f\"\\nHuman: {user_input}\")\n",
        "\n",
        "        # Run the graph with the input\n",
        "        result = run_profile_creation(user_input)\n",
        "\n",
        "        # Extract and print assistant's response\n",
        "        if result and 'messages' in result:\n",
        "            assistant_response = result['messages'][-1]['content'] if result['messages'] else \"No response\"\n",
        "            print(f\"Assistant: {assistant_response}\")\n",
        "\n",
        "        # Optional: Print current state (for debugging)\n",
        "        print(\"\\nCurrent Profile State:\")\n",
        "        print(result.get('user_profile', 'No profile data yet'))\n",
        "\n",
        "        # Add a small pause for readability\n",
        "        asyncio.sleep(1)\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    simulate_conversation()\n",
        "\n",
        "# Additional interactive method for manual input\n",
        "def interactive_agent_chat():\n",
        "    print(\"Panaversity Profile Creator - Interactive Chat\")\n",
        "    print(\"Type 'exit' to end the conversation\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nYou: \")\n",
        "\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        result = run_profile_creation(user_input)\n",
        "\n",
        "        # Extract and print assistant's response\n",
        "        if result and 'messages' in result:\n",
        "            assistant_response = result['messages'][-1]['content'] if result['messages'] else \"No response\"\n",
        "            print(f\"Assistant: {assistant_response}\")\n",
        "\n",
        "        # Print current profile state\n",
        "        print(\"\\nCurrent Profile State:\")\n",
        "        print(result.get('user_profile', 'No profile data yet'))\n",
        "\n",
        "# Uncomment the method you want to run\n",
        "simulate_conversation()\n",
        "# interactive_agent_chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "Izoakr3seAo_",
        "outputId": "72aba3cd-d8fe-4b71-b300-abd87c570397"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Panaversity Profile Creator Agent\n",
            "-------------------------------\n",
            "\n",
            "Human: Hi, I want to create my Panaversity profile\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/jupyter_client/session.py:151: RuntimeWarning: coroutine 'run_profile_creation_async' was never awaited\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "asyncio.run() cannot be called from a running event loop",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6d020d4378de>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Main execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0msimulate_conversation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Additional interactive method for manual input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-6d020d4378de>\u001b[0m in \u001b[0;36msimulate_conversation\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Run the graph with the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_profile_creation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Extract and print assistant's response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-6d020d4378de>\u001b[0m in \u001b[0;36mrun_profile_creation\u001b[0;34m(input_message)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Synchronous wrapper for async method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_profile_creation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_message\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_profile_creation_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Interactive conversation simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \"\"\"\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m     34\u001b[0m             \"asyncio.run() cannot be called from a running event loop\")\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "async def run_profile_creation(graph, input_message):\n",
        "    thread = {\"configurable\": {\"thread_id\": \"unique_user_session\"}}\n",
        "    inputs = {\n",
        "        \"messages\": [{\"role\": \"human\", \"content\": input_message}],\n",
        "        \"user_profile\": {}\n",
        "    }\n",
        "    result = await graph.ainvoke(inputs, thread)\n",
        "    return result\n",
        "\n",
        "# Main conversation simulation\n",
        "async def main():\n",
        "    graph = create_profile_graph()\n",
        "\n",
        "    # Conversation flow\n",
        "    conversation = [\n",
        "        \"Hi, I want to create my Panaversity profile\",\n",
        "        \"My name is Ahmed Khan\",\n",
        "        \"Here's my LinkedIn profile: https://linkedin.com/in/sample\",\n",
        "        \"My skills are Python, Machine Learning, and AI\"\n",
        "    ]\n",
        "\n",
        "    for message in conversation:\n",
        "        print(f\"\\nHuman: {message}\")\n",
        "        result = await run_profile_creation(graph, message)\n",
        "\n",
        "        # Print assistant's response\n",
        "        if result and 'messages' in result:\n",
        "            assistant_response = result['messages'][-1]['content']\n",
        "            print(f\"Assistant: {assistant_response}\")\n",
        "\n",
        "        # Print current profile state\n",
        "        print(\"Current Profile:\", result.get('user_profile', {}))\n",
        "\n",
        "# Run the conversation\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "yDafPuVqgaW3",
        "outputId": "38075b9e-fc7d-47f6-99dd-7fa4cba86743"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "asyncio.run() cannot be called from a running event loop",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-01d614cb4765>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Run the conversation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \"\"\"\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m     34\u001b[0m             \"asyncio.run() cannot be called from a running event loop\")\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from typing import TypedDict, Optional, Dict, Any, List\n",
        "from langgraph.graph import StateGraph, END, START\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langchain_core.tools import BaseTool\n",
        "from pydantic import Field\n",
        "from typing_extensions import override\n",
        "\n",
        "# State Definition\n",
        "class State(TypedDict):\n",
        "    messages: List[Dict[str, str]]\n",
        "    user_profile: Dict[str, Any]\n",
        "    profile_completion_stage: Optional[str]\n",
        "\n",
        "# Tools for Profile Creation\n",
        "class ProfileTool(BaseTool):\n",
        "    name: str = \"profile_creator\"\n",
        "    description: str = \"Tool to guide profile creation and data collection\"\n",
        "\n",
        "    @override\n",
        "    def _run(self, state: State, *args: Any, **kwargs: Any) -> Any:\n",
        "        # Simulate profile data collection and validation\n",
        "        profile = state.get(\"user_profile\", {})\n",
        "        messages = state.get(\"messages\", [])\n",
        "        last_message = messages[-1]['content'] if messages else \"\"\n",
        "\n",
        "        # Simple profile data extraction logic\n",
        "        if \"name\" not in profile and \"name is\" in last_message.lower():\n",
        "            name = last_message.split(\"name is\")[-1].strip()\n",
        "            profile[\"name\"] = name\n",
        "            return {\"user_profile\": profile, \"message\": f\"Great! I've added {name} to your profile.\"}\n",
        "\n",
        "        if \"linkedin\" in last_message.lower():\n",
        "            profile[\"linkedin\"] = last_message\n",
        "            profile[\"linkedin_data\"] = {\n",
        "                \"name\": \"Professional User\",\n",
        "                \"skills\": [\"Programming\", \"AI\", \"Machine Learning\"]\n",
        "            }\n",
        "            return {\"user_profile\": profile, \"message\": \"LinkedIn profile link processed.\"}\n",
        "\n",
        "        if \"skills\" in last_message.lower():\n",
        "            skills = last_message.split(\"skills\")[-1].strip()\n",
        "            profile[\"skills\"] = skills.split(\",\")\n",
        "            return {\"user_profile\": profile, \"message\": f\"Skills {skills} added to profile.\"}\n",
        "\n",
        "        return {\"message\": \"Please provide more specific information about your profile.\"}\n",
        "\n",
        "# Graph Creation Function\n",
        "def create_profile_graph():\n",
        "    graph_builder = StateGraph(State)\n",
        "\n",
        "    # Initialize node\n",
        "    def initialize_node(state: State):\n",
        "        return {\n",
        "            \"messages\": state.get(\"messages\", []) + [\n",
        "                {\"role\": \"assistant\", \"content\": \"Welcome to Panaversity Profile Creator! Let's build your professional profile.\"}\n",
        "            ],\n",
        "            \"user_profile\": {},\n",
        "            \"profile_completion_stage\": \"start\"\n",
        "        }\n",
        "\n",
        "    # Chatbot interaction node\n",
        "    def chatbot_node(state: State):\n",
        "        return {\n",
        "            \"messages\": state[\"messages\"] + [\n",
        "                {\"role\": \"assistant\", \"content\": \"How can I help you complete your profile today?\"}\n",
        "            ]\n",
        "        }\n",
        "\n",
        "    # Tools\n",
        "    tools = [ProfileTool()]\n",
        "\n",
        "    # Add nodes\n",
        "    graph_builder.add_node(\"initialize\", initialize_node)\n",
        "    graph_builder.add_node(\"chatbot\", chatbot_node)\n",
        "    graph_builder.add_node(\"tools\", ToolNode(tools=tools))\n",
        "\n",
        "    # Routing logic\n",
        "    def route_tools(state: State):\n",
        "        profile = state.get(\"user_profile\", {})\n",
        "        if not profile.get(\"name\"):\n",
        "            return \"tools\"\n",
        "        if not profile.get(\"linkedin\"):\n",
        "            return \"tools\"\n",
        "        if not profile.get(\"skills\"):\n",
        "            return \"tools\"\n",
        "        return END\n",
        "\n",
        "    # Edge configuration\n",
        "    graph_builder.add_conditional_edges(\n",
        "        \"chatbot\",\n",
        "        route_tools,\n",
        "        {\"tools\": \"tools\", END: END}\n",
        "    )\n",
        "    graph_builder.add_edge(START, \"initialize\")\n",
        "    graph_builder.add_edge(\"initialize\", \"chatbot\")\n",
        "    graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "\n",
        "    return graph_builder.compile(checkpointer=MemorySaver())\n",
        "\n",
        "# Async interaction method\n",
        "async def run_profile_creation(graph, input_message):\n",
        "    thread = {\"configurable\": {\"thread_id\": \"unique_user_session\"}}\n",
        "    inputs = {\n",
        "        \"messages\": [{\"role\": \"human\", \"content\": input_message}],\n",
        "        \"user_profile\": {}\n",
        "    }\n",
        "    result = await graph.ainvoke(inputs, thread)\n",
        "    return result\n",
        "\n",
        "# Main conversation simulation\n",
        "async def main():\n",
        "    graph = create_profile_graph()\n",
        "\n",
        "    # Conversation flow\n",
        "    conversation = [\n",
        "        \"Hi, I want to create my Panaversity profile\",\n",
        "        \"My name is Ahmed Khan\",\n",
        "        \"Here's my LinkedIn profile: https://linkedin.com/in/sample\",\n",
        "        \"My skills are Python, Machine Learning, and AI\"\n",
        "    ]\n",
        "\n",
        "    for message in conversation:\n",
        "        print(f\"\\nHuman: {message}\")\n",
        "        result = await run_profile_creation(graph, message)\n",
        "\n",
        "        # Print assistant's response\n",
        "        if result and 'messages' in result:\n",
        "            assistant_response = result['messages'][-1]['content']\n",
        "            print(f\"Assistant: {assistant_response}\")\n",
        "\n",
        "        # Print current profile state\n",
        "        print(\"Current Profile:\", result.get('user_profile', {}))\n",
        "\n",
        "# Run the conversation\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "ulfwox3VgGsg",
        "outputId": "58792a11-45d6-4c33-d137-8ce285b7508a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/tokenize.py:527: RuntimeWarning: coroutine 'run_profile_creation_async' was never awaited\n",
            "  pseudomatch = _compile(PseudoToken).match(line, pos)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "asyncio.run() cannot be called from a running event loop",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-4eaaaca11351>\u001b[0m in \u001b[0;36m<cell line: 137>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;31m# Run the conversation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \"\"\"\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m     34\u001b[0m             \"asyncio.run() cannot be called from a running event loop\")\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "m1PwpqMublH8"
      }
    }
  ]
}